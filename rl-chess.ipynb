{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Covert to FEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-09-24T06:14:04.625560Z",
     "iopub.status.busy": "2025-09-24T06:14:04.625327Z",
     "iopub.status.idle": "2025-09-24T06:14:14.120546Z",
     "shell.execute_reply": "2025-09-24T06:14:14.119072Z",
     "shell.execute_reply.started": "2025-09-24T06:14:04.625539Z"
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting chess\n",
      "  Downloading chess-1.11.2.tar.gz (6.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Building wheels for collected packages: chess\n",
      "  Building wheel for chess (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for chess: filename=chess-1.11.2-py3-none-any.whl size=147775 sha256=0cff6bd67c0940c61cb230e4b390c8d116b2d3eaa32a08d89bf0e5d379bb3673\n",
      "  Stored in directory: /root/.cache/pip/wheels/fb/5d/5c/59a62d8a695285e59ec9c1f66add6f8a9ac4152499a2be0113\n",
      "Successfully built chess\n",
      "Installing collected packages: chess\n",
      "Successfully installed chess-1.11.2\n"
     ]
    }
   ],
   "source": [
    "!pip install chess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-09-24T06:14:14.123192Z",
     "iopub.status.busy": "2025-09-24T06:14:14.122902Z",
     "iopub.status.idle": "2025-09-24T06:14:14.530679Z",
     "shell.execute_reply": "2025-09-24T06:14:14.529716Z",
     "shell.execute_reply.started": "2025-09-24T06:14:14.123165Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import bz2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import os, io, re, json, glob\n",
    "from typing import Iterator, Optional, List, Dict, Any\n",
    "import chess, chess.pgn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-24T06:14:14.532788Z",
     "iopub.status.busy": "2025-09-24T06:14:14.532070Z",
     "iopub.status.idle": "2025-09-24T06:15:37.370428Z",
     "shell.execute_reply": "2025-09-24T06:15:37.369411Z",
     "shell.execute_reply.started": "2025-09-24T06:14:14.532751Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game at 0th index: b'\n"
     ]
    }
   ],
   "source": [
    "with bz2.open(\"/kaggle/input/raw-chess-games-pgn/lichess_db_standard_rated_2014-08.pgn.bz2\", \"rb\") as f:\n",
    "    data = f.read()\n",
    "\n",
    "data = str(data) # Convert binary data into string for easier functionality\n",
    "raw_games = data.split('[Event') # Split the data into chess games using the '[Event' string\n",
    "print(\"Game at 0th index: %s\" % raw_games[0])\n",
    "del raw_games[0] # The first index isn't a game\n",
    "del data # Remove binary string to save memory\n",
    "\n",
    "eval_games = []\n",
    "for game in raw_games:\n",
    "    if game.find('eval') != -1:\n",
    "        eval_games.append(game)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-09-24T06:15:37.372183Z",
     "iopub.status.busy": "2025-09-24T06:15:37.371857Z",
     "iopub.status.idle": "2025-09-24T06:15:37.377405Z",
     "shell.execute_reply": "2025-09-24T06:15:37.376421Z",
     "shell.execute_reply.started": "2025-09-24T06:15:37.372150Z"
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \"Rated Bullet game\"]\\n[Site \"https://lichess.org/s3CHmrgH\"]\\n[White \"JekyllHyde\"]\\n[Black \"Maconouchi\"]\\n[Result \"1-0\"]\\n[UTCDate \"2014.07.31\"]\\n[UTCTime \"22:01:10\"]\\n[WhiteElo \"1627\"]\\n[BlackElo \"1662\"]\\n[WhiteRatingDiff \"+52\"]\\n[BlackRatingDiff \"-13\"]\\n[ECO \"B01\"]\\n[Opening \"Scandinavian Defense: Modern Variation #2\"]\\n[TimeControl \"60+0\"]\\n[Termination \"Normal\"]\\n\\n1. e4 { [%eval 0.2] } 1... d5 { [%eval 0.47] } 2. exd5 { [%eval 0.45] } 2... Nf6 { [%eval 0.58] } 3. Nc3 { [%eval 0.38] } 3... Nxd5 { [%eval 0.32] } 4. Nf3 { [%eval 0.27] } 4... Nc6 { [%eval 0.52] } 5. d4 { [%eval 0.43] } 5... e6 { [%eval 0.51] } 6. Be3 { [%eval 0.13] } 6... Bb4 { [%eval 0.26] } 7. Bd2 { [%eval 0.22] } 7... O-O { [%eval 0.29] } 8. a3 { [%eval -0.04] } 8... Bxc3 { [%eval 0.0] } 9. Bxc3 { [%eval -0.49] } 9... Nxc3 { [%eval -0.42] } 10. bxc3 { [%eval -0.43] } 10... Qf6 { [%eval 0.03] } 11. Bd3 { [%eval -0.27] } 11... h6?! { [%eval 0.57] } 12. O-O { [%eval 0.41] } 12... Re8 { [%eval 0.65] } 13. Qe2 { [%eval 0.61] } 13... b6 { [%eval 0.68] } 14. Rae1 { [%eval 0.46] } 14... Bb7 { [%eval 0.38] } 15. c4? { [%eval -1.46] } 15... Rab8? { [%eval 0.37] } 16. c3 { [%eval 0.39] } 16... Ne7 { [%eval 0.48] } 17. Ne5 { [%eval 0.31] } 17... c5? { [%eval 1.56] } 18. Nd7 { [%eval 1.52] } 18... Rbc8?? { [%eval 9.65] } 19. Nxf6+ { [%eval 9.61] } 1-0\\n\\n\n"
     ]
    }
   ],
   "source": [
    "print(eval_games[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-24T06:15:37.401895Z",
     "iopub.status.busy": "2025-09-24T06:15:37.401591Z",
     "iopub.status.idle": "2025-09-24T06:26:57.626814Z",
     "shell.execute_reply": "2025-09-24T06:26:57.625620Z",
     "shell.execute_reply.started": "2025-09-24T06:15:37.401864Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] 100000 games, 6731478 moves → /kaggle/working/move_dataset.jsonl\n"
     ]
    }
   ],
   "source": [
    "EVAL_RE = re.compile(r\"\\[%eval\\s+([+#\\-0-9\\.]+)\\]\")\n",
    "\n",
    "def extract_moves_from_pgn(path_in: str, path_out: str, limit=None):\n",
    "    n_games, n_rows = 0, 0\n",
    "    with bz2.open(path_in, \"rb\") as f:\n",
    "        fh = io.TextIOWrapper(f, encoding=\"utf-8\", errors=\"ignore\")\n",
    "        with open(path_out, \"w\", encoding=\"utf-8\") as fout:\n",
    "            while True:\n",
    "                game = chess.pgn.read_game(fh)\n",
    "                if game is None:\n",
    "                    break\n",
    "                n_games += 1\n",
    "                board = game.board()\n",
    "                node = game\n",
    "                ply = 0\n",
    "                while node.variations:\n",
    "                    next_node = node.variation(0)\n",
    "                    move = next_node.move\n",
    "                    fen_before = board.fen()\n",
    "                    move_uci = move.uci()\n",
    "                    fout.write(json.dumps({\n",
    "                        \"fen\": fen_before,\n",
    "                        \"move\": move_uci,\n",
    "                        \"side_to_move\": 1 if board.turn else -1\n",
    "                    }) + \"\\n\")\n",
    "                    board.push(move)\n",
    "                    node = next_node\n",
    "                    ply += 1\n",
    "                    n_rows += 1\n",
    "                if limit and n_games >= limit:\n",
    "                    break\n",
    "    print(f\"[OK] {n_games} games, {n_rows} moves → {path_out}\")\n",
    "\n",
    "# Demo với 1 file lichess .pgn.bz2\n",
    "extract_moves_from_pgn(\n",
    "    \"/kaggle/input/raw-chess-games-pgn/lichess_db_standard_rated_2014-08.pgn.bz2\",\n",
    "    \"/kaggle/working/move_dataset.jsonl\",\n",
    "    limit=100000\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T10:29:16.216304Z",
     "iopub.status.busy": "2025-10-08T10:29:16.216048Z",
     "iopub.status.idle": "2025-10-08T10:29:24.242439Z",
     "shell.execute_reply": "2025-10-08T10:29:24.241685Z",
     "shell.execute_reply.started": "2025-10-08T10:29:16.216283Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-chess\n",
      "  Downloading python_chess-1.999-py3-none-any.whl.metadata (776 bytes)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
      "Collecting chess<2,>=1 (from python-chess)\n",
      "  Downloading chess-1.11.2.tar.gz (6.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m51.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Downloading python_chess-1.999-py3-none-any.whl (1.4 kB)\n",
      "Building wheels for collected packages: chess\n",
      "  Building wheel for chess (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for chess: filename=chess-1.11.2-py3-none-any.whl size=147775 sha256=d33db72334501ad9eb01278e763239495eddd7bbd737236006378f61765d4a35\n",
      "  Stored in directory: /root/.cache/pip/wheels/fb/5d/5c/59a62d8a695285e59ec9c1f66add6f8a9ac4152499a2be0113\n",
      "Successfully built chess\n",
      "Installing collected packages: chess, python-chess\n",
      "Successfully installed chess-1.11.2 python-chess-1.999\n"
     ]
    }
   ],
   "source": [
    "!pip install python-chess tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T10:29:24.244227Z",
     "iopub.status.busy": "2025-10-08T10:29:24.244006Z",
     "iopub.status.idle": "2025-10-08T10:30:02.903046Z",
     "shell.execute_reply": "2025-10-08T10:30:02.902398Z",
     "shell.execute_reply.started": "2025-10-08T10:29:24.244209Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned dataset: /kaggle/working/chess_prep/move_dataset_clean.jsonl\n",
      "Kept: 5968500, Removed: 762978, Total: 6731478\n"
     ]
    }
   ],
   "source": [
    "import os, json\n",
    "\n",
    "data_path = \"/kaggle/input/move-dt/move_dataset.jsonl\"\n",
    "out_dir = \"/kaggle/working/chess_prep\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "seen = set()\n",
    "kept = 0\n",
    "removed = 0\n",
    "\n",
    "out_file = os.path.join(out_dir, \"move_dataset_clean.jsonl\")\n",
    "with open(data_path, \"r\") as fin, open(out_file, \"w\") as fout:\n",
    "    for line in fin:\n",
    "        obj = json.loads(line)\n",
    "        key = (obj[\"fen\"], obj[\"move\"], obj[\"side_to_move\"])\n",
    "        if key in seen:\n",
    "            removed += 1\n",
    "            continue\n",
    "        seen.add(key)\n",
    "        kept += 1\n",
    "        fout.write(json.dumps(obj) + \"\\n\")\n",
    "\n",
    "print(f\"Saved cleaned dataset: {out_file}\")\n",
    "print(f\"Kept: {kept}, Removed: {removed}, Total: {kept+removed}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T10:30:02.904056Z",
     "iopub.status.busy": "2025-10-08T10:30:02.903772Z",
     "iopub.status.idle": "2025-10-08T10:30:47.527346Z",
     "shell.execute_reply": "2025-10-08T10:30:47.526433Z",
     "shell.execute_reply.started": "2025-10-08T10:30:02.904029Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved train.jsonl: 4774800 samples\n",
      "Saved val.jsonl: 596850 samples\n",
      "Saved test.jsonl: 596850 samples\n"
     ]
    }
   ],
   "source": [
    "import os, json, random\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "def split_jsonl_dataset(\n",
    "    in_file: str,\n",
    "    out_dir: str,\n",
    "    seed: int = 42,\n",
    "    train_ratio: float = 0.8,\n",
    "    val_ratio: float = 0.1,\n",
    ") -> None:\n",
    "\n",
    "    with open(in_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        data: List[Dict[str, Any]] = [json.loads(line) for line in f]\n",
    "\n",
    "    random.seed(seed)\n",
    "    random.shuffle(data)\n",
    "\n",
    "    n = len(data)\n",
    "    n_train = int(train_ratio * n)\n",
    "    n_val   = int(val_ratio * n)\n",
    "\n",
    "    splits = {\n",
    "        \"train.jsonl\": data[:n_train],\n",
    "        \"val.jsonl\":   data[n_train:n_train + n_val],\n",
    "        \"test.jsonl\":  data[n_train + n_val:],\n",
    "    }\n",
    "\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    for name, subset in splits.items():\n",
    "        path = os.path.join(out_dir, name)\n",
    "        with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "            for obj in subset:\n",
    "                f.write(json.dumps(obj, ensure_ascii=False) + \"\\n\")\n",
    "        print(f\"Saved {name}: {len(subset)} samples\")\n",
    "\n",
    "\n",
    "split_jsonl_dataset(\"/kaggle/working/chess_prep/move_dataset_clean.jsonl\", \"/kaggle/working/chess_prep\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T10:37:44.534316Z",
     "iopub.status.busy": "2025-10-08T10:37:44.533646Z",
     "iopub.status.idle": "2025-10-08T10:37:44.552128Z",
     "shell.execute_reply": "2025-10-08T10:37:44.551586Z",
     "shell.execute_reply.started": "2025-10-08T10:37:44.534294Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 4672\n"
     ]
    }
   ],
   "source": [
    "import chess, json, os\n",
    "\n",
    "def build_alphazero_4672():\n",
    "    move2id = {}\n",
    "    id2move = {}\n",
    "    idx = 0\n",
    "    \n",
    "    directions = [\n",
    "        (1,0),(0,1),(-1,0),(0,-1),   # rook\n",
    "        (1,1),(-1,1),(1,-1),(-1,-1)  # bishop\n",
    "    ]\n",
    "    knight_offsets = [(2,1),(1,2),(-1,2),(-2,1),(-2,-1),(-1,-2),(1,-2),(2,-1)]\n",
    "    promo_pieces = [chess.ROOK, chess.BISHOP, chess.KNIGHT]  # queen promotion coi như mặc định\n",
    "    \n",
    "    for sq in chess.SQUARES:\n",
    "        r0, c0 = divmod(sq, 8)\n",
    "        \n",
    "        # sliding moves (56 = 8 directions × 7 steps)\n",
    "        for dr,dc in directions:\n",
    "            for k in range(1,8):\n",
    "                r, c = r0+dr*k, c0+dc*k\n",
    "                if 0 <= r < 8 and 0 <= c < 8:\n",
    "                    to_sq = r*8+c\n",
    "                    uci = chess.Move(sq, to_sq).uci()\n",
    "                else:\n",
    "                    uci = f\"null_{sq}_{dr}_{dc}_{k}\"  # dummy move\n",
    "                move2id[uci] = idx\n",
    "                id2move[idx] = uci\n",
    "                idx += 1\n",
    "\n",
    "        # knight moves (8)\n",
    "        for dr,dc in knight_offsets:\n",
    "            r, c = r0+dr, c0+dc\n",
    "            if 0 <= r < 8 and 0 <= c < 8:\n",
    "                to_sq = r*8+c\n",
    "                uci = chess.Move(sq, to_sq).uci()\n",
    "            else:\n",
    "                uci = f\"null_knight_{sq}_{dr}_{dc}\"\n",
    "            move2id[uci] = idx\n",
    "            id2move[idx] = uci\n",
    "            idx += 1\n",
    "\n",
    "        # underpromotions (9 = 3 dirs × 3 promos)\n",
    "        for dc in [-1,0,1]:\n",
    "            for promo in promo_pieces:\n",
    "                if r0 == 6:  # white pawn promotion\n",
    "                    r, c = r0+1, c0+dc\n",
    "                    if 0 <= c < 8:\n",
    "                        to_sq = r*8+c\n",
    "                        uci = chess.Move(sq, to_sq, promotion=promo).uci()\n",
    "                    else:\n",
    "                        uci = f\"null_promo_w_{sq}_{dc}_{promo}\"\n",
    "                elif r0 == 1:  # black pawn promotion\n",
    "                    r, c = r0-1, c0+dc\n",
    "                    if 0 <= c < 8:\n",
    "                        to_sq = r*8+c\n",
    "                        uci = chess.Move(sq, to_sq, promotion=promo).uci()\n",
    "                    else:\n",
    "                        uci = f\"null_promo_b_{sq}_{dc}_{promo}\"\n",
    "                else:\n",
    "                    uci = f\"null_promo_{sq}_{dc}_{promo}\"\n",
    "                move2id[uci] = idx\n",
    "                id2move[idx] = uci\n",
    "                idx += 1\n",
    "\n",
    "    print(f\"Vocab size: {len(move2id)}\")  # phải ra 4672\n",
    "    return move2id, id2move\n",
    "\n",
    "move2id, id2move = build_alphazero_4672()\n",
    "\n",
    "WORKDIR = \"/kaggle/working/chess_prep\"\n",
    "with open(os.path.join(WORKDIR, \"move_vocab_4672.json\"), \"w\") as f:\n",
    "    json.dump(move2id, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T10:44:16.585107Z",
     "iopub.status.busy": "2025-10-08T10:44:16.584689Z",
     "iopub.status.idle": "2025-10-08T10:44:19.140995Z",
     "shell.execute_reply": "2025-10-08T10:44:19.140316Z",
     "shell.execute_reply.started": "2025-10-08T10:44:16.585081Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"dedup_kept\": 5968500,\n",
      "  \"dedup_removed\": 762978,\n",
      "  \"vocab_size\": 4672,\n",
      "  \"val_total\": 596850,\n",
      "  \"val_unknown\": 1551,\n",
      "  \"val_unknown_rate\": 0.002598642875094245,\n",
      "  \"test_total\": 596850,\n",
      "  \"test_unknown\": 1555,\n",
      "  \"test_unknown_rate\": 0.00260534472648069\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "def unknown_rate(path, move2id):\n",
    "    total = 0\n",
    "    unk = 0\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            total += 1\n",
    "            m = json.loads(line)[\"move\"]\n",
    "            if m not in move2id:\n",
    "                unk += 1\n",
    "    rate = (unk / total) if total else 0.0\n",
    "    return total, unk, rate\n",
    "\n",
    "val_tot, val_unk, val_rate = unknown_rate(VAL, move2id)\n",
    "test_tot, test_unk, test_rate = unknown_rate(TEST, move2id)\n",
    "\n",
    "stats = {\n",
    "    \"dedup_kept\": 5968500,        # điền giá trị bạn đã in được, hoặc đọc lại từ file nếu muốn\n",
    "    \"dedup_removed\": 762978,\n",
    "    \"vocab_size\": len(move2id),\n",
    "    \"val_total\": val_tot, \"val_unknown\": val_unk, \"val_unknown_rate\": val_rate,\n",
    "    \"test_total\": test_tot, \"test_unknown\": test_unk, \"test_unknown_rate\": test_rate,\n",
    "}\n",
    "\n",
    "with open(STATS, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(stats, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(json.dumps(stats, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T10:40:53.913870Z",
     "iopub.status.busy": "2025-10-08T10:40:53.913529Z",
     "iopub.status.idle": "2025-10-08T10:40:53.924679Z",
     "shell.execute_reply": "2025-10-08T10:40:53.923986Z",
     "shell.execute_reply.started": "2025-10-08T10:40:53.913845Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os, json, numpy as np, torch, chess\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class FenMoveDataset(Dataset):\n",
    "    def __init__(self, path: str, move2id: dict):\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            self.samples = [json.loads(line) for line in f]\n",
    "        self.move2id = move2id\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        obj = self.samples[idx]\n",
    "        x, board = self.fen_to_planes(obj[\"fen\"])\n",
    "        y = self.move2id.get(obj[\"move\"], -1)\n",
    "        mask = self.legal_mask(board)\n",
    "        return x.astype(np.float32), y, mask\n",
    "\n",
    "    @staticmethod\n",
    "    def fen_to_planes(fen: str):\n",
    "        board = chess.Board(fen)\n",
    "        planes = []\n",
    "        piece_types = [chess.PAWN,chess.KNIGHT,chess.BISHOP,\n",
    "                       chess.ROOK,chess.QUEEN,chess.KING]\n",
    "        for color in [chess.WHITE, chess.BLACK]:\n",
    "            for pt in piece_types:\n",
    "                m = np.zeros((8,8), dtype=np.float32)\n",
    "                for sq in board.pieces(pt, color):\n",
    "                    r,c = divmod(63 - sq, 8)\n",
    "                    m[r,c] = 1.0\n",
    "                planes.append(m)\n",
    "        # side to move\n",
    "        planes.append(np.full((8,8), 1.0 if board.turn==chess.WHITE else 0.0, dtype=np.float32))\n",
    "        # castling rights\n",
    "        wk = np.full((8,8), board.has_kingside_castling_rights(chess.WHITE), dtype=np.float32)\n",
    "        wq = np.full((8,8), board.has_queenside_castling_rights(chess.WHITE), dtype=np.float32)\n",
    "        bk = np.full((8,8), board.has_kingside_castling_rights(chess.BLACK), dtype=np.float32)\n",
    "        bq = np.full((8,8), board.has_queenside_castling_rights(chess.BLACK), dtype=np.float32)\n",
    "        planes += [wk,wq,bk,bq]\n",
    "        # en passant\n",
    "        ep = np.zeros((8,8), dtype=np.float32)\n",
    "        if board.ep_square is not None:\n",
    "            r,c = divmod(63 - board.ep_square, 8)\n",
    "            ep[r,c] = 1.0\n",
    "        planes.append(ep)\n",
    "        return np.stack(planes, axis=0), board\n",
    "\n",
    "    def legal_mask(self, board: chess.Board):\n",
    "        mask = np.zeros(len(self.move2id), dtype=np.float32)\n",
    "        for m in board.legal_moves:\n",
    "            uci = m.uci()\n",
    "            if uci in self.move2id:\n",
    "                mask[self.move2id[uci]] = 1.0\n",
    "        return mask\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    xs, ys, masks = zip(*batch)\n",
    "    return (\n",
    "        torch.from_numpy(np.stack(xs)).float(),\n",
    "        torch.tensor(ys, dtype=torch.long),\n",
    "        torch.from_numpy(np.stack(masks)).float()\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T10:40:55.324388Z",
     "iopub.status.busy": "2025-10-08T10:40:55.323740Z",
     "iopub.status.idle": "2025-10-08T10:40:55.329112Z",
     "shell.execute_reply": "2025-10-08T10:40:55.328465Z",
     "shell.execute_reply.started": "2025-10-08T10:40:55.324369Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class PolicyNet(nn.Module):\n",
    "    def __init__(self, vocab_size: int):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(18, 128, 3, padding=1), nn.ReLU(),\n",
    "            nn.Conv2d(128,128,3,padding=1), nn.ReLU(),\n",
    "            nn.Conv2d(128,128,3,padding=1), nn.ReLU(),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(128*8*8, 1024), nn.ReLU(),\n",
    "            nn.Linear(1024, vocab_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(self.conv(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T10:40:59.773490Z",
     "iopub.status.busy": "2025-10-08T10:40:59.772794Z",
     "iopub.status.idle": "2025-10-08T10:40:59.782142Z",
     "shell.execute_reply": "2025-10-08T10:40:59.781435Z",
     "shell.execute_reply.started": "2025-10-08T10:40:59.773467Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class MaskedCrossEntropyLoss(nn.Module):\n",
    "    def forward(self, logits, target, legal_mask):\n",
    "        masked_logits = logits.masked_fill(legal_mask==0, float(\"-inf\"))\n",
    "        log_probs = F.log_softmax(masked_logits, dim=-1)\n",
    "        B,V = logits.shape\n",
    "        idx = torch.arange(B, device=logits.device)\n",
    "        valid = (target >= 0) & (target < V)\n",
    "        tgt_logp = log_probs[idx, target]\n",
    "        tgt_logp[~valid] = 0.0\n",
    "        if valid.any():\n",
    "            return -(tgt_logp[valid].mean())\n",
    "        else:\n",
    "            return torch.tensor(0.0, device=logits.device)\n",
    "\n",
    "# ============================================================\n",
    "# 4. Trainer\n",
    "# ============================================================\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self, model, train_dl, val_dl, device=\"cpu\", lr=1e-3):\n",
    "        self.model = model.to(device)\n",
    "        self.train_dl = train_dl\n",
    "        self.val_dl = val_dl\n",
    "        self.device = device\n",
    "        self.opt = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "        self.criterion = MaskedCrossEntropyLoss()\n",
    "\n",
    "    def run_epoch(self, train=True):\n",
    "        self.model.train(train)\n",
    "        total_loss, total = 0.0, 0\n",
    "        with torch.set_grad_enabled(train):\n",
    "            for X,y,mask in self.train_dl if train else self.val_dl:\n",
    "                X,y,mask = X.to(self.device), y.to(self.device), mask.to(self.device)\n",
    "                logits = self.model(X)\n",
    "                loss = self.criterion(logits, y, mask)\n",
    "                if train:\n",
    "                    self.opt.zero_grad()\n",
    "                    loss.backward()\n",
    "                    self.opt.step()\n",
    "                bs = X.size(0)\n",
    "                total_loss += loss.item() * bs\n",
    "                total += bs\n",
    "        return total_loss / max(total,1)\n",
    "\n",
    "    def fit(self, epochs=5):\n",
    "        for ep in range(epochs):\n",
    "            tr = self.run_epoch(True)\n",
    "            va = self.run_epoch(False)\n",
    "            print(f\"Epoch {ep}: train {tr:.4f} | val {va:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T10:41:00.694992Z",
     "iopub.status.busy": "2025-10-08T10:41:00.694280Z",
     "iopub.status.idle": "2025-10-08T10:41:05.211252Z",
     "shell.execute_reply": "2025-10-08T10:41:05.210707Z",
     "shell.execute_reply.started": "2025-10-08T10:41:00.694966Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn, torch.nn.functional as F, math\n",
    "from torch.amp import autocast, GradScaler\n",
    "from pathlib import Path\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, ch):\n",
    "        super().__init__()\n",
    "        self.f = nn.Sequential(\n",
    "            nn.Conv2d(ch, ch, 3, padding=1, bias=False), nn.BatchNorm2d(ch), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(ch, ch, 3, padding=1, bias=False), nn.BatchNorm2d(ch),\n",
    "        )\n",
    "        self.act = nn.ReLU(inplace=True)\n",
    "    def forward(self, x): \n",
    "        return self.act(x + self.f(x))\n",
    "\n",
    "class ChessResNet(nn.Module):\n",
    "    def __init__(self, in_ch=18, ch=160, n=12, vocab=100000):\n",
    "        super().__init__()\n",
    "        self.stem = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, ch, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(ch), nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.trunk = nn.Sequential(*[ResBlock(ch) for _ in range(n)])\n",
    "        self.policy = nn.Sequential(\n",
    "            nn.Conv2d(ch, 32, 1), nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(32*8*8, vocab)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        h = self.trunk(self.stem(x))\n",
    "        return self.policy(h)\n",
    "\n",
    "def masked_ce(logits, targets, legal, label_smoothing=0.05):\n",
    "    # CE chỉ tính trên legal moves + có label smoothing để bớt overfit\n",
    "    masked = torch.full_like(logits, float(\"-inf\"))\n",
    "    for i, ids in enumerate(legal):\n",
    "        if ids: masked[i, ids] = logits[i, ids]\n",
    "        else:   masked[i] = logits[i]  # fallback\n",
    "    return F.cross_entropy(masked, targets, label_smoothing=label_smoothing)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = ChessResNet(in_ch=18, ch=160, n=12, vocab=len(move2id)).to(device)\n",
    "\n",
    "opt = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=1e-4)\n",
    "scaler = GradScaler(\"cuda\", enabled=(device==\"cuda\"))\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate():\n",
    "    model.eval()\n",
    "    tot_loss=n=0; top1=top3=0\n",
    "    for xb, yb, legal in val_dl:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "\n",
    "        # sửa nhãn nếu không thuộc legal (hiếm)\n",
    "        safe_y = yb.clone()\n",
    "        for i,(yi,L) in enumerate(zip(yb.tolist(), legal)):\n",
    "            if (yi<0) or (yi not in L):\n",
    "                safe_y[i] = torch.tensor(L[0] if L else 0, device=device)\n",
    "\n",
    "        with autocast(\"cuda\", enabled=(device==\"cuda\")):\n",
    "            logits = model(xb)\n",
    "            loss = masked_ce(logits, safe_y, legal, label_smoothing=0.05)\n",
    "\n",
    "        B = xb.size(0); tot_loss += float(loss)*B; n += B\n",
    "\n",
    "        # Top-k trong legal\n",
    "        for i in range(B):\n",
    "            ids = legal[i] if legal[i] else torch.arange(logits.size(1)).tolist()\n",
    "            li = logits[i, ids]\n",
    "            k = min(3, len(ids))\n",
    "            topk = torch.topk(li, k=k).indices.cpu().tolist()\n",
    "            pred1 = ids[topk[0]]; gold = int(safe_y[i])\n",
    "            if pred1==gold: top1+=1\n",
    "            if gold in [ids[j] for j in topk]: top3+=1\n",
    "\n",
    "    loss = tot_loss/max(1,n); ppl = math.exp(min(20,loss))\n",
    "    return {\"val_loss\":loss, \"val_ppl\":ppl, \"val_top1\":top1/n, \"val_top3\":top3/n}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-27T09:01:06.336645Z",
     "iopub.status.busy": "2025-09-27T09:01:06.335932Z",
     "iopub.status.idle": "2025-09-27T16:54:38.721836Z",
     "shell.execute_reply": "2025-09-27T16:54:38.720792Z",
     "shell.execute_reply.started": "2025-09-27T09:01:06.336612Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded vocab size = 4672\n",
      "Epoch 0: train 2.4057 | val 2.2220\n",
      "Epoch 1: train 2.1585 | val 2.1600\n",
      "Epoch 2: train 2.0934 | val 2.1380\n",
      "Epoch 3: train 2.0508 | val 2.1252\n",
      "Epoch 4: train 2.0179 | val 2.1284\n",
      "Epoch 5: train 1.9902 | val 2.1310\n",
      "Epoch 6: train 1.9658 | val 2.1385\n",
      "Epoch 7: train 1.9430 | val 2.1536\n",
      "Epoch 8: train 1.9230 | val 2.1639\n",
      "Epoch 9: train 1.9050 | val 2.1719\n",
      "Epoch 10: train 1.8879 | val 2.1918\n",
      "Epoch 11: train 1.8722 | val 2.1997\n",
      "Epoch 12: train 1.8578 | val 2.2131\n",
      "Epoch 13: train 1.8442 | val 2.2415\n",
      "Epoch 14: train 1.8319 | val 2.2555\n",
      "Epoch 15: train 1.8209 | val 2.2911\n",
      "Epoch 16: train 1.8105 | val 2.2806\n",
      "Epoch 17: train 1.8005 | val 2.2900\n",
      "Epoch 18: train 1.7916 | val 2.3202\n",
      "Epoch 19: train 1.7839 | val 2.3145\n",
      "Epoch 20: train 1.7763 | val 2.3174\n",
      "Epoch 21: train 1.7699 | val 2.3459\n",
      "Epoch 22: train 1.7631 | val 2.3700\n",
      "Epoch 23: train 1.7580 | val 2.3918\n",
      "Epoch 24: train 1.7524 | val 2.3872\n",
      "Epoch 25: train 1.7471 | val 2.4099\n",
      "Epoch 26: train 1.7427 | val 2.4247\n",
      "Epoch 27: train 1.7388 | val 2.4883\n",
      "Epoch 28: train 1.7350 | val 2.5060\n",
      "Epoch 29: train 1.7316 | val 2.4940\n",
      "✅ Model saved to /kaggle/working/chess_prep/policy_model.pt\n"
     ]
    }
   ],
   "source": [
    "# === MAIN TRAINING CELL ===\n",
    "\n",
    "WORKDIR = \"/kaggle/working/chess_prep\"\n",
    "TRAIN_PATH = os.path.join(WORKDIR, \"train.jsonl\")\n",
    "VAL_PATH   = os.path.join(WORKDIR, \"val.jsonl\")\n",
    "VOCAB_PATH = os.path.join(WORKDIR, \"move_vocab_4672.json\")\n",
    "\n",
    "# Load vocab\n",
    "with open(VOCAB_PATH, \"r\") as f:\n",
    "    move2id = json.load(f)\n",
    "vocab_size = len(move2id)\n",
    "print(f\"Loaded vocab size = {vocab_size}\")\n",
    "\n",
    "# Dataset + DataLoader\n",
    "train_ds = FenMoveDataset(TRAIN_PATH, move2id)\n",
    "val_ds   = FenMoveDataset(VAL_PATH, move2id)\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=256, shuffle=True, num_workers=2, collate_fn=collate_fn)\n",
    "val_dl   = DataLoader(val_ds, batch_size=256, shuffle=False, num_workers=2, collate_fn=collate_fn)\n",
    "\n",
    "# Model + Trainer\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = PolicyNet(vocab_size)\n",
    "trainer = Trainer(model, train_dl, val_dl, device=device, lr=1e-3)\n",
    "\n",
    "# Train\n",
    "trainer.fit(epochs=30)\n",
    "\n",
    "# Save model checkpoint\n",
    "CKPT_PATH = os.path.join(WORKDIR, \"policy_model.pt\")\n",
    "torch.save({\n",
    "    \"model_state\": model.state_dict(),\n",
    "    \"optimizer_state\": trainer.opt.state_dict(),\n",
    "    \"vocab\": move2id\n",
    "}, CKPT_PATH)\n",
    "\n",
    "print(f\"Model saved to {CKPT_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-09-26T06:58:14.615549Z",
     "iopub.status.idle": "2025-09-26T06:58:14.615780Z",
     "shell.execute_reply": "2025-09-26T06:58:14.615691Z",
     "shell.execute_reply.started": "2025-09-26T06:58:14.615682Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def predict_move(fen: str, topk=5):\n",
    "    model.eval()\n",
    "    x,_ = fen_to_planes(fen)\n",
    "    x = torch.from_numpy(x).unsqueeze(0).float().to(device)\n",
    "    with autocast(\"cuda\", enabled=(device==\"cuda\")):\n",
    "        logits = model(x)\n",
    "    # lọc theo legal\n",
    "    board = chess.Board(fen)\n",
    "    ids = [move2id[m.uci()] for m in board.legal_moves if m.uci() in move2id]\n",
    "    li = logits[0, ids]\n",
    "    k = min(topk, len(ids))\n",
    "    idx = torch.topk(li, k=k).indices.cpu().tolist()\n",
    "    inv_vocab = {v:k for k,v in move2id.items()}\n",
    "    return [inv_vocab[ids[i]] for i in idx]\n",
    "\n",
    "# ví dụ\n",
    "print(predict_move(\"rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1\", topk=5))\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 1092242,
     "sourceId": 1837247,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8335305,
     "sourceId": 13155414,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 467171,
     "modelInstanceId": 450822,
     "sourceId": 601557,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
